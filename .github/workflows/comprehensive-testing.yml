name: Comprehensive Testing Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM
  workflow_dispatch:

permissions:
  contents: read
  actions: read
  security-events: write
  id-token: write
  checks: write
  pull-requests: write

env:
  CARGO_TERM_COLOR: always
  RUST_VERSION: stable
  RUSTFLAGS: -D warnings
  RUST_BACKTRACE: 1

jobs:
  # Test matrix for different configurations
  test-matrix:
    name: Test Matrix (${{ matrix.rust }} - ${{ matrix.features }} - ${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30

    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        rust: [stable, beta]
        features: ['default', 'all', 'minimal']
        include:
          - os: ubuntu-latest
            rust: nightly
            features: 'experimental'
            experimental: true
        exclude:
          - os: windows-latest
            features: 'experimental'
          - os: macos-latest
            features: 'minimal'

    continue-on-error: ${{ matrix.experimental || false }}

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U test_user -d test_db"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd="redis-cli ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: ${{ matrix.rust }}
          profile: minimal
          override: true
      - name: Install dependencies
        run: cargo fetch --workspace
      - name: Build workspace
        run: cargo build --workspace --all-features
      - name: Run tests
        run: cargo test --workspace --all-features -- --nocapture
      - name: Run clippy (lint)
        run: cargo clippy --workspace --all-features -- -D warnings

      - name: Cache cargo dependencies
        uses: Swatinem/rust-cache@v2
        with:
          key: ${{ matrix.os }}-${{ matrix.rust }}-${{ matrix.features }}

      - name: Install test dependencies
        if: matrix.os == 'ubuntu-latest'
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client redis-tools
          cargo install cargo-llvm-cov --locked
          cargo install cargo-nextest --locked

      - name: Setup test environment
        env:
          DATABASE_URL: postgres://test_user:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
        run: |
          # Create test configuration
          mkdir -p test-config
          cat > test-config/test.toml << EOF
          [server]
          host = "127.0.0.1"
          port = 8080

          [database]
          url = "$DATABASE_URL"

          [redis]
          url = "$REDIS_URL"

          [security]
          jwt_secret = "test_secret_key_for_testing_only"
          encryption_key = "test_encryption_key_32_characters"

          [monitoring]
          enabled = false
          EOF

      - name: Configure feature set
        id: features
        run: |
          case "${{ matrix.features }}" in
            "all")
              echo "cargo_features=--all-features" >> $GITHUB_OUTPUT
              ;;
            "minimal")
              echo "cargo_features=--no-default-features --features core" >> $GITHUB_OUTPUT
              ;;
            "experimental")
              echo "cargo_features=--features post-quantum-crypto,ml-threat-detection" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "cargo_features=" >> $GITHUB_OUTPUT
              ;;
          esac

      - name: Run unit tests
        env:
          DATABASE_URL: postgres://test_user:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
          CONFIG_PATH: test-config/test.toml
        run: |
          echo "🧪 Running unit tests with ${{ matrix.features }} features..."
          if command -v cargo-nextest >/dev/null 2>&1; then
            cargo nextest run ${{ steps.features.outputs.cargo_features }} --workspace
          else
            cargo test ${{ steps.features.outputs.cargo_features }} --workspace
          fi

      - name: Run integration tests
        if: matrix.os == 'ubuntu-latest' && matrix.rust == 'stable'
        env:
          DATABASE_URL: postgres://test_user:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
          CONFIG_PATH: test-config/test.toml
        run: |
          echo "🔗 Running integration tests..."
          if find . -name "*integration*.rs" | grep -q .; then
            cargo test ${{ steps.features.outputs.cargo_features }} --test '*integration*'
          else
            echo "No integration tests found"
          fi

      - name: Generate test coverage
        if: matrix.os == 'ubuntu-latest' && matrix.rust == 'stable' && matrix.features == 'all'
        env:
          DATABASE_URL: postgres://test_user:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
          CONFIG_PATH: test-config/test.toml
        run: |
          echo "📊 Generating test coverage..."
          cargo llvm-cov --all-features --workspace --lcov --output-path lcov.info

      - name: Upload coverage to Codecov
        if: matrix.os == 'ubuntu-latest' && matrix.rust == 'stable' && matrix.features == 'all'
        uses: codecov/codecov-action@v3
        with:
          files: lcov.info
          fail_ci_if_error: false
          verbose: true

  # Property-based and fuzzing tests
  property-tests:
    name: Property-Based Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Cache cargo dependencies
        uses: Swatinem/rust-cache@v2

      - name: Install cargo-fuzz
        run: cargo install cargo-fuzz --locked

      - name: Run property-based tests
        run: |
          echo "🎲 Running property-based tests..."

          # Run proptest tests if they exist
          if grep -r "proptest" --include="*.rs" .; then
            cargo test --all-features proptest
          fi

          # Run quickcheck tests if they exist
          if grep -r "quickcheck" --include="*.rs" .; then
            cargo test --all-features quickcheck
          fi

      - name: Run fuzzing tests
        run: |
          echo "🔀 Running fuzzing tests..."

          # Check for fuzz targets
          if [ -d "auth-service/fuzz" ]; then
            cd auth-service
            timeout 300s cargo fuzz run token_parser -- -max_total_time=300 || true
            timeout 300s cargo fuzz run input_validator -- -max_total_time=300 || true
          fi

          if [ -d "input-validation/fuzz" ]; then
            cd input-validation
            timeout 300s cargo fuzz run sanitizer -- -max_total_time=300 || true
          fi

      - name: Upload fuzzing artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: fuzzing-artifacts
          path: |
            **/fuzz/artifacts/
            **/fuzz/corpus/
          retention-days: 7

  # Load and performance tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: perf_user
          POSTGRES_PASSWORD: perf_password
          POSTGRES_DB: perf_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U perf_user -d perf_db"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd="redis-cli ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo dependencies
        uses: Swatinem/rust-cache@v2

      - name: Install performance testing tools
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client redis-tools apache2-utils
          cargo install cargo-criterion --locked

      - name: Build release binaries
        run: |
          echo "🔨 Building release binaries..."
          cargo build --release --workspace

      - name: Run benchmark tests
        env:
          DATABASE_URL: postgres://perf_user:perf_password@localhost:5432/perf_db
          REDIS_URL: redis://localhost:6379
        run: |
          echo "⚡ Running benchmark tests..."

          # Run criterion benchmarks if they exist
          if find . -name "*.rs" -path "*/benches/*" | grep -q .; then
            cargo criterion --output-format json > benchmark-results.json
          fi

          # Run custom performance benchmarks
          for script in scripts/performance/*.sh; do
            if [ -f "$script" ]; then
              echo "Running performance script: $script"
              timeout 300s bash "$script" || echo "Script $script timed out or failed"
            fi
          done

      - name: Analyze performance results
        run: |
          echo "📊 Analyzing performance results..."

          if [ -f "benchmark-results.json" ]; then
            # Basic performance analysis using jq if available, otherwise simple output
            if command -v jq >/dev/null 2>&1; then
              echo "Performance Summary:"
              jq -r '.results[]? | "\(.id // "Unknown"): \(.mean.estimate // 0) ns"' benchmark-results.json 2>/dev/null || echo "Could not parse benchmark results"
            else
              echo "Performance results available in benchmark-results.json"
              head -20 benchmark-results.json 2>/dev/null || echo "Could not read benchmark results"
            fi
          fi

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results
          path: |
            benchmark-results.json
            performance-reports/
          retention-days: 30

  # Security-focused tests
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo dependencies
        uses: Swatinem/rust-cache@v2

      - name: Install security testing tools
        run: |
          cargo install cargo-audit --locked
          cargo install cargo-deny --locked
          cargo install cargo-geiger --locked

      - name: Run security audit
        run: |
          echo "🔒 Running security audit..."
          cargo audit --json > security-audit.json

          # Check for high-severity vulnerabilities
          HIGH_VULNS=$(jq '.vulnerabilities.found | length' security-audit.json)
          echo "Found $HIGH_VULNS vulnerabilities"

          if [ "$HIGH_VULNS" -gt 0 ]; then
            echo "❌ Security vulnerabilities found!"
            jq '.vulnerabilities.found[]' security-audit.json
          fi

      - name: Run dependency policy check
        run: |
          echo "📋 Checking dependency policies..."
          cargo deny check

      - name: Analyze unsafe code usage
        run: |
          echo "⚠️ Analyzing unsafe code usage..."
          cargo geiger --output-format Json > unsafe-analysis.json || true

          # Summarize results
          if [ -f "unsafe-analysis.json" ]; then
            echo "Unsafe Code Analysis:"
            if command -v jq >/dev/null 2>&1; then
              jq -r '.packages[]? | select(.unsafetyStats.unsafe > 0) | "\(.name // "Unknown"): \(.unsafetyStats.unsafe) unsafe blocks"' unsafe-analysis.json 2>/dev/null || echo "Could not parse unsafe analysis results"
              total_unsafe=$(jq '[.packages[]?.unsafetyStats.unsafe] | add // 0' unsafe-analysis.json 2>/dev/null || echo 0)
              echo "Total unsafe blocks: $total_unsafe"
            else
              echo "Unsafe analysis results available in unsafe-analysis.json"
              head -20 unsafe-analysis.json 2>/dev/null || echo "Could not read unsafe analysis results"
            fi
          fi

      - name: Run security-focused tests
        run: |
          echo "🛡️ Running security-focused tests..."

          # Run tests tagged with security
          cargo test --all-features security -- --nocapture || true

          # Run validation tests
          if find . -name "*security*test*.rs" | grep -q .; then
            cargo test --all-features --test '*security*'
          fi

      - name: Upload security artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-analysis
          path: |
            security-audit.json
            unsafe-analysis.json
          retention-days: 30

  # Test documentation and examples
  doc-tests:
    name: Documentation Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo dependencies
        uses: Swatinem/rust-cache@v2

      - name: Test documentation
        run: |
          echo "📚 Running documentation tests..."
          cargo test --doc --all-features --workspace

      - name: Check documentation generation
        run: |
          echo "📖 Checking documentation generation..."
          cargo doc --no-deps --all-features --workspace

      - name: Test examples
        run: |
          echo "🎯 Testing examples..."

          for example in examples/*/; do
            if [ -d "$example" ] && [ -f "$example/Cargo.toml" ]; then
              echo "Testing example: $(basename "$example")"
              cd "$example"
              cargo check --all-features || echo "Example $(basename "$example") check failed"
              cargo test --all-features || echo "Example $(basename "$example") tests failed"
              cd - > /dev/null
            fi
          done

  # Test result summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-matrix, property-tests, performance-tests, security-tests, doc-tests]
    if: always()
    timeout-minutes: 5

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: test-artifacts

      - name: Generate test summary
        run: |
          echo "📊 Comprehensive Testing Summary" >> $GITHUB_STEP_SUMMARY
          echo "=================================" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "- Test Matrix: ${{ needs.test-matrix.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Property Tests: ${{ needs.property-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Performance Tests: ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Security Tests: ${{ needs.security-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Documentation Tests: ${{ needs.doc-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Count artifacts
          if [ -d "test-artifacts" ]; then
            ARTIFACT_COUNT=$(find test-artifacts -type f | wc -l)
            echo "## Generated Artifacts: $ARTIFACT_COUNT files" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Determine overall status
          FAILED_JOBS=""
          [ "${{ needs.test-matrix.result }}" != "success" ] && FAILED_JOBS="$FAILED_JOBS test-matrix"
          [ "${{ needs.property-tests.result }}" != "success" ] && FAILED_JOBS="$FAILED_JOBS property-tests"
          [ "${{ needs.performance-tests.result }}" != "success" ] && FAILED_JOBS="$FAILED_JOBS performance-tests"
          [ "${{ needs.security-tests.result }}" != "success" ] && FAILED_JOBS="$FAILED_JOBS security-tests"
          [ "${{ needs.doc-tests.result }}" != "success" ] && FAILED_JOBS="$FAILED_JOBS doc-tests"

          if [ -z "$FAILED_JOBS" ]; then
            echo "✅ **All comprehensive tests passed!**" >> $GITHUB_STEP_SUMMARY
            exit 0
          else
            echo "❌ **Failed jobs:** $FAILED_JOBS" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

